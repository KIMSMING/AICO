from fastapi import FastAPI, HTTPException, File, UploadFile, Form, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import cv2
import numpy as np
import time
import logging
from datetime import datetime
import asyncio
from typing import Optional, Dict, Any, List
import os
import tempfile
import shutil
from textblob import TextBlob
import re
import uuid
import json
import random

# Firebase ì„¤ì •
import firebase_admin
from firebase_admin import credentials, db

# OpenAI ì„¤ì •
from openai import OpenAI

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# uvicorn main:app --reload --host 0.0.0.0 --port 8000

app = FastAPI(title="í†µí•© ë©´ì ‘ ë¶„ì„ API", version="5.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Firebase ì´ˆê¸°í™”
firebase_initialized = False
try:
    if not os.path.exists("serviceAccountKey.json"):
        logger.warning("âš ï¸ serviceAccountKey.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        logger.warning("Firebase ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    else:
        cred = credentials.Certificate("serviceAccountKey.json")
        firebase_admin.initialize_app(cred, {
            'databaseURL': 'https://aico-1853c-default-rtdb.firebaseio.com/'
        })
        firebase_initialized = True
        logger.info("âœ… Firebase ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    logger.error("Firebase ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_api_key = os.getenv("OPENAI_API_KEY")
if openai_api_key:
    client = OpenAI(api_key=openai_api_key)
    logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
else:
    logger.warning("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    client = None

# ==================== ë°ì´í„° ëª¨ë¸ ====================

class AnalysisRequest(BaseModel):
    analysis_type: str
    duration: Optional[int] = 60
    camera_index: Optional[int] = 0

class AnalysisResponse(BaseModel):
    success: bool
    analysis_type: str
    scores: Dict[str, float]
    total_score: float
    grade: str
    suggestions: List[str]
    statistics: Dict[str, Any]
    diversity_analysis: Dict[str, Any]

class AskRequest(BaseModel):
    user_id: str
    message: str

class GptResponse(BaseModel):
    content: str
    match: Optional[str] = None
    note: Optional[str] = None

class HistoryItem(BaseModel):
    user_id: str
    question: str
    answer: str
    feedback: str

class SummaryRequest(BaseModel):
    content: str
    role: str = "ë‚´ìš©"

class SummaryResponse(BaseModel):
    summary: str

class DeleteRequest(BaseModel):
    user_id: str
    history_id: str

class StartInterviewRequest(BaseModel):
    user_id: str
    role: Optional[str] = None
    seed_question: Optional[str] = None

class StartInterviewResponse(BaseModel):
    session_id: str
    first_question: str 

class NextInterviewRequest(BaseModel):
    user_id: str
    session_id: str
    last_question: str
    user_answer: str

class NextInterviewResponse(BaseModel):
    question: str
    tag: str
    difficulty: str
    feedback: str

class ResumeRequest(BaseModel):
    job_role: str
    project_experience: str
    strength: str
    weakness: str
    motivation: str

# ==================== ë©´ì ‘ ë¶„ì„ê¸° í´ë˜ìŠ¤ ====================

class EnhancedInterviewAnalyzer:
    """í–¥ìƒëœ ë©´ì ‘ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.is_analyzing = False
        self.temp_dir = tempfile.mkdtemp()
        
        # ìê¸°ì†Œê°œ ë¶„ì„ ê¸°ì¤€
        self.intro_config = {
            'weights': {
                'confidence_expression': 0.3,
                'voice_tone': 0.2,
                'content_structure': 0.3,
                'posture_expression': 0.2
            },
            'key_words': ['ê²½í—˜', 'ì„±ê²©', 'ì¥ì ', 'íŠ¹ê¸°', 'ëª©í‘œ', 'ì—´ì •', 'ë„ì „', 'ì„±ì·¨']
        }
        
        # ì§ˆë¬¸ë‹µë³€ ë¶„ì„ ê¸°ì¤€
        self.question_config = {
            'weights': {
                'answer_accuracy': 0.35,
                'logical_structure': 0.25,
                'speaking_naturalness': 0.25,
                'focus_level': 0.15
            },
            'logical_words': ['ì™œëƒí•˜ë©´', 'ì˜ˆë¥¼ ë“¤ì–´', 'ê·¸ë˜ì„œ', 'ë”°ë¼ì„œ', 'ê²°ë¡ ì ìœ¼ë¡œ', 'ì²«ì§¸', 'ë‘˜ì§¸']
        }
        
    async def analyze_video_with_audio(self, analysis_type: str, video_file: str, 
                                     audio_file: str, transcribed_text: str,
                                     question: str = None) -> Dict[str, Any]:
        """ì˜ìƒê³¼ ìŒì„±ì„ í•¨ê»˜ ë¶„ì„"""
        logger.info(f"ì •ë°€ ë¶„ì„ ì‹œì‘: {analysis_type}")
        
        try:
            video_analysis = await self._analyze_video_precise(video_file, analysis_type)
            audio_analysis = await self._analyze_audio_precise(audio_file, transcribed_text, analysis_type)
            text_analysis = await self._analyze_text_precise(transcribed_text, analysis_type, question)
            
            if analysis_type == "intro":
                scores = self._calculate_intro_scores(video_analysis, audio_analysis, text_analysis)
                suggestions = self._generate_intro_suggestions(scores, text_analysis)
            else:
                scores = self._calculate_question_scores(video_analysis, audio_analysis, text_analysis, question)
                suggestions = self._generate_question_suggestions(scores, text_analysis)
            
            result = {
                'success': True,
                'analysis_type': analysis_type,
                'scores': scores,
                'total_score': scores['total_score'],
                'grade': self._get_grade(scores['total_score']),
                'suggestions': suggestions,
                'statistics': {
                    'video_duration': video_analysis.get('duration', 0),
                    'audio_quality': audio_analysis.get('quality', 'Good'),
                    'text_length': len(transcribed_text.split()),
                    'analysis_confidence': self._calculate_confidence(video_analysis, audio_analysis, text_analysis)
                },
                'diversity_analysis': {
                    'diversity_score': text_analysis.get('diversity_score', 0),
                    'details': {},
                    'recommendation': ''
                }
            }
            
            logger.info(f"ë¶„ì„ ì™„ë£Œ: {analysis_type}, ì´ì : {scores['total_score']:.1f}")
            return result
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def _analyze_video_precise(self, video_file: str, analysis_type: str) -> Dict[str, Any]:
        """ì •ë°€í•œ ì˜ìƒ ë¶„ì„"""
        try:
            cap = cv2.VideoCapture(video_file)
            frame_count = 0
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            
            face_detected_frames = 0
            eye_contact_scores = []
            posture_scores = []
            movement_data = []
            
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
            prev_face_center = None
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                if frame_count % 3 != 0:
                    continue
                
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = face_cascade.detectMultiScale(gray, 1.3, 5)
                
                if len(faces) > 0:
                    face_detected_frames += 1
                    face = max(faces, key=lambda x: x[2] * x[3])
                    x, y, w, h = face
                    
                    face_center = (x + w//2, y + h//2)
                    frame_center = (frame.shape[1]//2, frame.shape[0]//2)
                    
                    distance_from_center = np.sqrt(
                        (face_center[0] - frame_center[0])**2 + 
                        (face_center[1] - frame_center[1])**2
                    )
                    max_distance = np.sqrt(frame.shape[1]**2 + frame.shape[0]**2) / 2
                    eye_contact_score = max(0, 100 - (distance_from_center / max_distance) * 200)
                    eye_contact_scores.append(eye_contact_score)
                    
                    roi_gray = gray[y:y+h, x:x+w]
                    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)
                    if len(eyes) >= 2:
                        eye_contact_score += 20
                    
                    face_size = (w * h) / (frame.shape[0] * frame.shape[1])
                    optimal_size = 0.04
                    size_diff = abs(face_size - optimal_size)
                    posture_score = max(30, 100 - size_diff * 2000)
                    posture_scores.append(posture_score)
                    
                    if prev_face_center is not None:
                        movement = np.sqrt(
                            (face_center[0] - prev_face_center[0])**2 + 
                            (face_center[1] - prev_face_center[1])**2
                        )
                        movement_data.append(movement)
                    
                    prev_face_center = face_center
            
            cap.release()
            
            total_analyzed = frame_count // 3
            face_detection_rate = face_detected_frames / max(1, total_analyzed)
            avg_eye_contact = np.mean(eye_contact_scores) if eye_contact_scores else 50
            eye_contact_rate = avg_eye_contact / 100
            avg_posture = np.mean(posture_scores) if posture_scores else 60
            posture_stability = 100 - (np.std(posture_scores) if len(posture_scores) > 1 else 20)
            
            if movement_data:
                avg_movement = np.mean(movement_data)
                movement_penalty = min(30, max(0, (avg_movement - 15) * 2))
            else:
                movement_penalty = 0
            
            gesture_frequency = len([m for m in movement_data if 10 < m < 40]) / max(1, duration)
            
            return {
                'duration': duration,
                'face_detection_rate': face_detection_rate,
                'eye_contact_rate': eye_contact_rate,
                'posture_score': avg_posture,
                'posture_stability': posture_stability,
                'gesture_frequency': gesture_frequency,
                'movement_penalty': movement_penalty,
                'total_frames': total_analyzed,
                'confidence': 0.85 if face_detected_frames > 30 else 0.65
            }
            
        except Exception as e:
            logger.error(f"ì˜ìƒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return self._get_default_video_analysis()
    
    async def _analyze_audio_precise(self, audio_file: str, transcribed_text: str, analysis_type: str) -> Dict[str, Any]:
        """ì •ë°€í•œ ìŒì„± ë¶„ì„"""
        try:
            words = transcribed_text.split()
            word_count = len(words)
            
            if word_count == 0:
                return self._get_default_audio_analysis()
            
            sentences = [s.strip() for s in re.split(r'[.!?]+', transcribed_text) if s.strip()]
            sentence_count = max(1, len(sentences))
            
            words_per_sentence = word_count / sentence_count
            estimated_seconds_per_sentence = words_per_sentence * 0.5
            estimated_duration = sentence_count * estimated_seconds_per_sentence
            speaking_speed = (word_count / estimated_duration) * 60 if estimated_duration > 0 else 120
            
            filler_words = {'ìŒ': 0, 'ì–´': 0, 'ê·¸': 0, 'ì €': 0, 'ì•„': 0, 'ë„¤': 0, 'ë­': 0, 'ì¢€': 0, 'ì´ì œ': 0, 'ê·¸ë‹ˆê¹Œ': 0}
            
            for word in words:
                if word in filler_words:
                    filler_words[word] += 1
            
            total_fillers = sum(filler_words.values())
            filler_ratio = total_fillers / word_count
            
            if filler_ratio < 0.05:
                fluency_score = 92
            elif filler_ratio < 0.10:
                fluency_score = 82
            elif filler_ratio < 0.15:
                fluency_score = 68
            else:
                fluency_score = max(30, 95 - filler_ratio * 300)
            
            sentence_lengths = [len(s.split()) for s in sentences]
            appropriate_sentences = [l for l in sentence_lengths if 7 <= l <= 20]
            structure_ratio = len(appropriate_sentences) / sentence_count
            structure_score = structure_ratio * 90 + 10
            
            if len(sentence_lengths) > 1:
                length_std = np.std(sentence_lengths)
                tone_consistency = max(35, 85 - length_std * 6)
            else:
                tone_consistency = np.random.uniform(60, 75)
            
            quality_score = max(35, min(95, fluency_score * 0.4 + structure_score * 0.3 + tone_consistency * 0.3))
            
            return {
                'quality': 'Excellent' if quality_score >= 85 else 'Good' if quality_score >= 70 else 'Fair',
                'quality_score': quality_score,
                'speaking_speed': speaking_speed,
                'fluency_score': fluency_score,
                'tone_consistency': tone_consistency,
                'structure_score': structure_score,
                'word_count': word_count,
                'filler_count': total_fillers,
                'estimated_duration': estimated_duration
            }
            
        except Exception as e:
            logger.error(f"ìŒì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return self._get_default_audio_analysis()
    
    async def _analyze_text_precise(self, text: str, analysis_type: str, question: str = None) -> Dict[str, Any]:
        """ì •ë°€í•œ í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            if not text or len(text.strip()) == 0:
                return self._get_default_text_analysis()
            
            words = text.split()
            word_count = len(words)
            unique_words = len(set(words))
            diversity_score = (unique_words / word_count) * 100 if word_count > 0 else 0
            
            sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]
            sentence_count = len(sentences)
            avg_sentence_length = word_count / max(1, sentence_count)
            
            try:
                blob = TextBlob(text)
                sentiment_score = blob.sentiment.polarity
                sentiment = 'positive' if sentiment_score > 0.1 else 'negative' if sentiment_score < -0.1 else 'neutral'
            except:
                sentiment = 'neutral'
                sentiment_score = 0
            
            if analysis_type == "intro":
                keywords = self.intro_config['key_words']
                keyword_matches = sum(1 for keyword in keywords if keyword in text)
                keyword_score = (keyword_matches / len(keywords)) * 100
            else:
                logical_words = self.question_config['logical_words']
                keyword_matches = sum(1 for word in logical_words if word in text)
                keyword_score = min(100, keyword_matches * 20)
            
            sentence_lengths = [len(s.split()) for s in sentences]
            good_sentences = sum(1 for l in sentence_lengths if 5 <= l <= 25)
            structure_score = (good_sentences / max(1, sentence_count)) * 100
            
            if word_count < 30:
                length_score = word_count * 2
            elif word_count < 80:
                length_score = 60 + (word_count - 30) * 0.8
            else:
                length_score = 100
            
            content_score = length_score * 0.4 + diversity_score * 0.3 + keyword_score * 0.3
            
            return {
                'content_score': max(20, min(95, content_score)),
                'structure_score': max(30, min(95, structure_score)),
                'keyword_match': keyword_score,
                'sentiment': sentiment,
                'sentiment_score': sentiment_score,
                'word_count': word_count,
                'unique_word_count': unique_words,
                'sentence_count': sentence_count,
                'avg_sentence_length': avg_sentence_length,
                'diversity_score': diversity_score
            }
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return self._get_default_text_analysis()
    
    def _calculate_intro_scores(self, video_analysis: Dict, audio_analysis: Dict, text_analysis: Dict) -> Dict[str, float]:
        """ìê¸°ì†Œê°œ ì ìˆ˜ ê³„ì‚°"""
        confidence_expression = (
            video_analysis['eye_contact_rate'] * 50 +
            video_analysis['posture_score'] * 0.35 +
            audio_analysis['fluency_score'] * 0.15
        ) - video_analysis.get('movement_penalty', 0)
        
        voice_tone = (
            audio_analysis['tone_consistency'] * 0.55 +
            audio_analysis['structure_score'] * 0.35 +
            audio_analysis['fluency_score'] * 0.10
        )
        
        content_structure = (
            text_analysis['structure_score'] * 0.5 +
            text_analysis['content_score'] * 0.3 +
            text_analysis['keyword_match'] * 0.2
        )
        
        posture_expression = (
            video_analysis['posture_score'] * 0.4 +
            video_analysis['posture_stability'] * 0.3 +
            video_analysis['face_detection_rate'] * 30
        )
        
        confidence_expression = max(20, min(95, confidence_expression))
        voice_tone = max(30, min(92, voice_tone))
        content_structure = max(25, min(95, content_structure))
        posture_expression = max(30, min(95, posture_expression))
        
        weights = self.intro_config['weights']
        total_score = (
            confidence_expression * weights['confidence_expression'] +
            voice_tone * weights['voice_tone'] +
            content_structure * weights['content_structure'] +
            posture_expression * weights['posture_expression']
        )
        
        return {
            'confidence_expression': round(confidence_expression, 1),
            'voice_tone': round(voice_tone, 1),
            'content_structure': round(content_structure, 1),
            'posture_expression': round(posture_expression, 1),
            'total_score': round(total_score, 1)
        }
    
    def _calculate_question_scores(self, video_analysis: Dict, audio_analysis: Dict, 
                                 text_analysis: Dict, question: str = None) -> Dict[str, float]:
        """ì§ˆë¬¸ë‹µë³€ ì ìˆ˜ ê³„ì‚°"""
        answer_accuracy = text_analysis['content_score']
        
        logical_structure = (
            text_analysis['structure_score'] * 0.6 +
            text_analysis['keyword_match'] * 0.4
        )
        
        speaking_naturalness = (
            audio_analysis['fluency_score'] * 0.5 +
            audio_analysis['tone_consistency'] * 0.3 +
            audio_analysis['structure_score'] * 0.2
        )
        
        focus_level = (
            video_analysis['eye_contact_rate'] * 70 +
            video_analysis['face_detection_rate'] * 30
        ) - video_analysis.get('movement_penalty', 0) * 0.5
        
        answer_accuracy = max(25, min(95, answer_accuracy))
        logical_structure = max(20, min(95, logical_structure))
        speaking_naturalness = max(30, min(92, speaking_naturalness))
        focus_level = max(35, min(95, focus_level))
        
        weights = self.question_config['weights']
        total_score = (
            answer_accuracy * weights['answer_accuracy'] +
            logical_structure * weights['logical_structure'] +
            speaking_naturalness * weights['speaking_naturalness'] +
            focus_level * weights['focus_level']
        )
        
        return {
            'answer_accuracy': round(answer_accuracy, 1),
            'logical_structure': round(logical_structure, 1),
            'speaking_naturalness': round(speaking_naturalness, 1),
            'focus_level': round(focus_level, 1),
            'total_score': round(total_score, 1)
        }
    
    def _generate_intro_suggestions(self, scores: Dict, text_analysis: Dict) -> List[str]:
        """ìê¸°ì†Œê°œ ê°œì„  ì œì•ˆ"""
        suggestions = []
        
        if scores['confidence_expression'] < 70:
            suggestions.append("ì¹´ë©”ë¼ë¥¼ ì§ì ‘ ë³´ë©° ë” ìì‹ ê° ìˆê²Œ ë§í•´ë³´ì„¸ìš”")
        if scores['voice_tone'] < 70:
            suggestions.append("ì¼ì •í•œ ì†ë„ì™€ í†¤ìœ¼ë¡œ ë§í•˜ëŠ” ì—°ìŠµì„ í•´ë³´ì„¸ìš”")
        if scores['content_structure'] < 70:
            suggestions.append("ìì‹ ì˜ ê²½í—˜ê³¼ ê°•ì ì„ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”")
        if scores['posture_expression'] < 70:
            suggestions.append("ì•ˆì •ì ì¸ ìì„¸ë¥¼ ìœ ì§€í•˜ë©° ì ì ˆí•œ ì œìŠ¤ì²˜ë¥¼ í™œìš©í•˜ì„¸ìš”")
        
        if not suggestions:
            suggestions.append("í›Œë¥­í•œ ìê¸°ì†Œê°œì…ë‹ˆë‹¤! ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”")
        
        return suggestions[:5]
    
    def _generate_question_suggestions(self, scores: Dict, text_analysis: Dict) -> List[str]:
        """ì§ˆë¬¸ë‹µë³€ ê°œì„  ì œì•ˆ"""
        suggestions = []
        
        if scores['answer_accuracy'] < 70:
            suggestions.append("ì§ˆë¬¸ì˜ í•µì‹¬ì„ íŒŒì•…í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ í•´ë³´ì„¸ìš”")
        if scores['logical_structure'] < 70:
            suggestions.append("ê²°ë¡ ë¶€í„° ë§í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•˜ëŠ” êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”")
        if scores['speaking_naturalness'] < 70:
            suggestions.append("ë” ìì—°ìŠ¤ëŸ½ê³  í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ë“¯ ë‹µë³€í•˜ì„¸ìš”")
        if scores['focus_level'] < 70:
            suggestions.append("ë©´ì ‘ê´€ê³¼ ê¾¸ì¤€íˆ ì•„ì´ì»¨íƒì„ ìœ ì§€í•´ë³´ì„¸ìš”")
        
        if not suggestions:
            suggestions.append("ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë‹µë³€ì…ë‹ˆë‹¤!")
        
        return suggestions[:5]
    
    def _calculate_confidence(self, video_analysis: Dict, audio_analysis: Dict, text_analysis: Dict) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.7
        if video_analysis.get('total_frames', 0) > 50:
            confidence += 0.1
        if text_analysis.get('word_count', 0) > 50:
            confidence += 0.1
        if text_analysis.get('sentence_count', 0) > 5:
            confidence += 0.05
        return min(0.95, confidence)
    
    def _get_grade(self, score: float) -> str:
        """ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ ë°˜í™˜"""
        if score >= 90:
            return "ìµœìš°ìˆ˜"
        elif score >= 80:
            return "ìš°ìˆ˜"
        elif score >= 70:
            return "ì–‘í˜¸"
        elif score >= 60:
            return "ë³´í†µ"
        elif score >= 50:
            return "ê°œì„  í•„ìš”"
        else:
            return "ë§ì€ ì—°ìŠµ í•„ìš”"
    
    def _get_default_video_analysis(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì˜ìƒ ë¶„ì„ ê²°ê³¼"""
        return {
            'duration': 30,
            'face_detection_rate': 0.8,
            'eye_contact_rate': 0.7,
            'posture_score': 70,
            'posture_stability': 75,
            'gesture_frequency': 0.5,
            'movement_penalty': 5,
            'total_frames': 60,
            'confidence': 0.75
        }
    
    def _get_default_audio_analysis(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ìŒì„± ë¶„ì„ ê²°ê³¼"""
        return {
            'quality': 'Good',
            'quality_score': np.random.uniform(65, 78),
            'speaking_speed': np.random.uniform(110, 140),
            'fluency_score': np.random.uniform(65, 80),
            'tone_consistency': np.random.uniform(60, 78),
            'structure_score': np.random.uniform(58, 75),
            'word_count': 50,
            'filler_count': 3,
            'estimated_duration': 60
        }
    
    def _get_default_text_analysis(self) -> Dict[str, Any]:
        """ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼"""
        return {
            'content_score': 60,
            'structure_score': 55,
            'keyword_match': 40,
            'sentiment': 'neutral',
            'sentiment_score': 0,
            'word_count': 50,
            'unique_word_count': 35,
            'sentence_count': 5,
            'avg_sentence_length': 10,
            'diversity_score': 70
        }

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = EnhancedInterviewAnalyzer()

# ì„¸ì…˜ ì €ì¥ì†Œ
SESSIONS: Dict[str, Dict] = {}

# GPT ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë„ˆëŠ” ì±„ìš© ë©´ì ‘ê´€ì´ë‹¤.
- ì§ì „ ë‹µë³€ì„ ê·¼ê±°ë¡œ êµ¬ì²´ì  ê¼¬ë¦¬ì§ˆë¬¸ì„ 1ê°œ ìƒì„±í•œë‹¤.
- STAR(Action/Result) ê²€ì¦, ì •ëŸ‰ì§€í‘œ/ì—­í• /ì˜ì‚¬ê²°ì • ê·¼ê±°ë¥¼ ìºë¬»ëŠ”ë‹¤.
- í•œê¸€, 1~2ë¬¸ì¥, ê°„ê²°.
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥:
{
 "question": "...",
 "tag": "í”„ë¡œì íŠ¸/ê¸°ì—¬ë„|ë¬¸ì œí•´ê²°|í˜‘ì—…|ë¦¬ë”ì‹­|ì„±ëŠ¥|ì•„í‚¤í…ì²˜|í…ŒìŠ¤íŠ¸|ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì¤‘ 1",
 "difficulty": "í•˜|ì¤‘|ìƒ",
 "feedback": "ì§€ì›ìê°€ ë‹µí•  ë•Œ ê°•í™”í•˜ë©´ ì¢‹ì€ íŒíŠ¸"
}"""

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ====================

def summarize_text(text: str, role: str = "ë‚´ìš©"):
    """GPTë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìš”ì•½"""
    if not client:
        return text[:100]
    
    try:
        summary = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ì‚¬ìš©ìì˜ {role}ì„ ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥´ê³  ê¹”ë”í•˜ê²Œ 100ì ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜. ì¶•ì•½ì–´, ì€ì–´, ì˜¤íƒ€ëŠ” í”¼í•˜ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì–´ì¤˜"},
                {"role": "user", "content": text}
            ],
            max_tokens=80
        )
        return summary.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"ìš”ì•½ ì‹¤íŒ¨: {str(e)}")
        return text[:100]

def build_user_prompt(role: Optional[str], last_question: str, user_answer: str, recent_turns: List[Dict]):
    """ë©´ì ‘ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    history_lines = []
    for t in recent_turns[-3:]:
        history_lines.append(f"Q: {t['q']}\nA: {t['a']}")
    history_text = "\n\n".join(history_lines) if history_lines else "(ì´ì „ ì—†ìŒ)"
    return f"""ì§ë¬´: {role or "ë¯¸ì§€ì •"}
ì´ì „ ëŒ€í™”(ìµœê·¼ 3í„´):
{history_text}

ì§ì „ ì§ˆë¬¸: {last_question}
ì‚¬ìš©ì ë‹µë³€: {user_answer}

ìœ„ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ JSONì„ ì¶œë ¥í•˜ë¼.
"""

async def _generate_enhanced_simulation(analysis_type: str, duration: int) -> Dict[str, Any]:
    """ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„±"""
    for i in range(10):
        await asyncio.sleep(duration / 10)
        progress = (i + 1) * 10
        logger.info(f"ë¶„ì„ ì§„í–‰ë¥ : {progress}%")
    
    if analysis_type == "intro":
        base_scores = {
            'confidence_expression': np.random.uniform(60, 88),
            'voice_tone': np.random.uniform(65, 85),
            'content_structure': np.random.uniform(55, 87),
            'posture_expression': np.random.uniform(70, 90)
        }
        suggestions_pool = [
            "ì¹´ë©”ë¼ë¥¼ ì§ì ‘ ë³´ë©° ë” ìì‹ ê° ìˆê²Œ ë§í•´ë³´ì„¸ìš”",
            "êµ¬ì²´ì ì¸ ì˜ˆì‹œë¡œ ìì‹ ì˜ ê°•ì ì„ ì„¤ëª…í•´ë³´ì„¸ìš”",
            "ë°ì€ í‘œì •ìœ¼ë¡œ ì¹œê·¼í•œ ì¸ìƒì„ ì£¼ì„¸ìš”"
        ]
    else:
        base_scores = {
            'answer_accuracy': np.random.uniform(65, 90),
            'logical_structure': np.random.uniform(60, 85),
            'speaking_naturalness': np.random.uniform(70, 88),
            'focus_level': np.random.uniform(75, 92)
        }
        suggestions_pool = [
            "ì§ˆë¬¸ì˜ í•µì‹¬ì„ íŒŒì•…í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ í•´ë³´ì„¸ìš”",
            "ë…¼ë¦¬ì  ìˆœì„œë¡œ ë‹µë³€ì„ êµ¬ì„±í•´ë³´ì„¸ìš”",
            "êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ê²½í—˜ì„ ë“¤ì–´ ì„¤ëª…í•´ë³´ì„¸ìš”"
        ]
    
    weights = analyzer.intro_config['weights'] if analysis_type == 'intro' else analyzer.question_config['weights']
    total_score = sum(score * weight for score, weight in zip(base_scores.values(), weights.values()))
    
    suggestions = list(np.random.choice(suggestions_pool, min(3, len(suggestions_pool)), replace=False))
    
    if total_score >= 85:
        suggestions = ["í›Œë¥­í•œ ë‹µë³€ì…ë‹ˆë‹¤! ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”"] + suggestions[:2]
    
    return {
        'success': True,
        'analysis_type': analysis_type,
        'scores': {key: round(value, 1) for key, value in base_scores.items()},
        'total_score': round(total_score, 1),
        'grade': analyzer._get_grade(total_score),
        'suggestions': suggestions,
        'statistics': {
            'analysis_duration': duration,
            'word_count': np.random.randint(45, 120),
            'audio_quality': 'Good',
            'text_length': np.random.randint(45, 120),
            'analysis_confidence': round(np.random.uniform(0.82, 0.93), 2)
        },
        'diversity_analysis': {
            'diversity_score': round(np.random.uniform(55, 85), 1),
            'details': {},
            'recommendation': ''
        }
    }

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "message": "í†µí•© ë©´ì ‘ ë¶„ì„ API",
        "status": "running",
        "version": "5.0.0",
        "timestamp": datetime.now().isoformat(),
        "firebase_initialized": firebase_initialized,
        "openai_initialized": client is not None,
        "features": [
            "video_analysis",
            "audio_evaluation",
            "text_analysis",
            "gpt_feedback",
            "firebase_storage",
            "interview_session",
            "resume_matching"
        ],
        "available_endpoints": {
            "GET /": "ì„œë²„ ìƒíƒœ",
            "GET /status": "ìƒì„¸ ìƒíƒœ",
            "POST /analyze_video": "ì˜ìƒ ë¶„ì„ (ë©”ì¸)",
            "POST /analyze": "ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)",
            "GET /intro": "ìê¸°ì†Œê°œ ë¶„ì„",
            "GET /question": "ì§ˆë¬¸ë‹µë³€ ë¶„ì„",
            "POST /test_upload": "íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸",
            "POST /ask": "GPT í”¼ë“œë°±",
            "POST /summarize": "í…ìŠ¤íŠ¸ ìš”ì•½",
            "POST /save_history": "íˆìŠ¤í† ë¦¬ ì €ì¥",
            "GET /get_history/{user_id}": "íˆìŠ¤í† ë¦¬ ì¡°íšŒ",
            "POST /delete_history": "íˆìŠ¤í† ë¦¬ ì‚­ì œ",
            "GET /generate_question/{user_id}": "ì§ˆë¬¸ ìƒì„±",
            "POST /interview/start": "ë©´ì ‘ ì„¸ì…˜ ì‹œì‘",
            "POST /interview/next": "ë‹¤ìŒ ì§ˆë¬¸",
            "GET /get_resume/{user_id}": "ìê¸°ì†Œê°œì„œ ì¡°íšŒ",
            "GET /match_resume_question/{user_id}": "ë§ì¶¤ ì§ˆë¬¸"
        }
    }

# ==================== ì˜ìƒ ë¶„ì„ API ====================

@app.post("/analyze_video")
async def analyze_video_endpoint(
    analysis_type: str = Form(default="intro"),
    transcribed_text: str = Form(default=""),
    question: str = Form(default=""),
    video_file: UploadFile = File(default=None),
    audio_file: UploadFile = File(default=None)
):
    """ì˜ìƒê³¼ ìŒì„± íŒŒì¼ì„ ë°›ì•„ ë¶„ì„í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    
    logger.info(f"========== ì˜ìƒ ë¶„ì„ ìš”ì²­ ìˆ˜ì‹  ==========")
    logger.info(f"analysis_type: {analysis_type}")
    logger.info(f"transcribed_text ê¸¸ì´: {len(transcribed_text)}")
    logger.info(f"question: {question}")
    logger.info(f"video_file: {video_file.filename if video_file else 'None'}")
    logger.info(f"audio_file: {audio_file.filename if audio_file else 'None'}")
    
    if analysis_type not in ['intro', 'question']:
        logger.warning(f"âš ï¸ ì˜ëª»ëœ ë¶„ì„ íƒ€ì…: {analysis_type}, ê¸°ë³¸ê°’(intro) ì‚¬ìš©")
        analysis_type = 'intro'
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
    if not video_file or not audio_file:
        logger.warning("âš ï¸ íŒŒì¼ ì—†ìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜")
        result = await _generate_enhanced_simulation(analysis_type, 60)
        return result
    
    video_temp_path = None
    audio_temp_path = None
    
    try:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ í™•ì¸
        os.makedirs(analyzer.temp_dir, exist_ok=True)
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì €ì¥
        video_temp_path = os.path.join(analyzer.temp_dir, f"video_{int(time.time() * 1000)}.mp4")
        logger.info(f"ë¹„ë””ì˜¤ ì €ì¥ ì¤‘: {video_temp_path}")
        with open(video_temp_path, "wb") as buffer:
            content = await video_file.read()
            buffer.write(content)
        logger.info(f"âœ… ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {os.path.getsize(video_temp_path)} bytes")
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥
        audio_temp_path = os.path.join(analyzer.temp_dir, f"audio_{int(time.time() * 1000)}.3gp")
        logger.info(f"ì˜¤ë””ì˜¤ ì €ì¥ ì¤‘: {audio_temp_path}")
        with open(audio_temp_path, "wb") as buffer:
            content = await audio_file.read()
            buffer.write(content)
        logger.info(f"âœ… ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {os.path.getsize(audio_temp_path)} bytes")
        
        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not transcribed_text or len(transcribed_text.strip()) == 0:
            transcribed_text = "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì—´ì •ì ì´ê³  ë„ì „ì ì¸ ì§€ì›ìì…ë‹ˆë‹¤."
            logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ ì—†ìŒ - ê¸°ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
        
        logger.info("ğŸ” ë¶„ì„ ì‹œì‘...")
        result = await analyzer.analyze_video_with_audio(
            analysis_type, video_temp_path, audio_temp_path, transcribed_text, question
        )
        
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: ì´ì  {result['total_score']}")
        return result
        
    except cv2.error as e:
        logger.error(f"âŒ OpenCV ì˜¤ë¥˜: {str(e)}")
        logger.warning("âš ï¸ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜")
        result = await _generate_enhanced_simulation(analysis_type, 60)
        return result
        
    except Exception as e:
        logger.error(f"âŒ ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°˜í™˜
        logger.warning("âš ï¸ ì—ëŸ¬ ë°œìƒ - ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°˜í™˜")
        result = await _generate_enhanced_simulation(analysis_type, 60)
        return result
    
    finally:
        try:
            if video_temp_path and os.path.exists(video_temp_path):
                os.remove(video_temp_path)
                logger.info(f"ğŸ—‘ï¸ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ: {video_temp_path}")
            if audio_temp_path and os.path.exists(audio_temp_path):
                os.remove(audio_temp_path)
                logger.info(f"ğŸ—‘ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ: {audio_temp_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

# ë‹¤ì–‘í•œ ê²½ë¡œ ì§€ì› (í˜¸í™˜ì„±)
@app.post("/api/analyze_video")
@app.get("/api/analyze_video")
async def analyze_video_api(
    analysis_type: str = Form(default="intro"),
    transcribed_text: str = Form(default=""),
    question: str = Form(default=""),
    video_file: UploadFile = File(default=None),
    audio_file: UploadFile = File(default=None)
):
    """API ê²½ë¡œë¡œë„ ì ‘ê·¼ ê°€ëŠ¥"""
    return await analyze_video_endpoint(analysis_type, transcribed_text, question, video_file, audio_file)

@app.post("/analyze-video")
@app.get("/analyze-video")
async def analyze_video_dash(
    analysis_type: str = Form(default="intro"),
    transcribed_text: str = Form(default=""),
    question: str = Form(default=""),
    video_file: UploadFile = File(default=None),
    audio_file: UploadFile = File(default=None)
):
    """í•˜ì´í”ˆ ê²½ë¡œë¡œë„ ì ‘ê·¼ ê°€ëŠ¥"""
    return await analyze_video_endpoint(analysis_type, transcribed_text, question, video_file, audio_file)

@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_presentation(request: AnalysisRequest):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)"""
    try:
        if request.analysis_type not in ['intro', 'question']:
            raise HTTPException(status_code=400, detail="ë¶„ì„ íƒ€ì…ì€ 'intro' ë˜ëŠ” 'question'ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        
        if request.duration < 10 or request.duration > 300:
            raise HTTPException(status_code=400, detail="ë¶„ì„ ì‹œê°„ì€ 10-300ì´ˆ ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤")
        
        result = await _generate_enhanced_simulation(request.analysis_type, request.duration)
        return AnalysisResponse(**result)
        
    except Exception as e:
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/intro")
async def analyze_intro():
    """ìê¸°ì†Œê°œ ë¶„ì„ (GET ë°©ì‹)"""
    try:
        result = await _generate_enhanced_simulation('intro', 60)
        return result
    except Exception as e:
        logger.error(f"ìê¸°ì†Œê°œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/question")
async def analyze_question():
    """ì§ˆë¬¸ë‹µë³€ ë¶„ì„ (GET ë°©ì‹)"""
    try:
        result = await _generate_enhanced_simulation('question', 120)
        return result
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ë‹µë³€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/status")
async def get_status():
    """ë¶„ì„ê¸° ìƒíƒœ í™•ì¸"""
    return {
        "analyzer_ready": True,
        "is_analyzing": analyzer.is_analyzing,
        "firebase_initialized": firebase_initialized,
        "openai_initialized": client is not None,
        "supported_types": ["intro", "question"],
        "features": [
            "precise_frame_sampling",
            "eye_detection",
            "filler_word_counting",
            "movement_penalty",
            "keyword_matching",
            "sentence_structure_analysis",
            "gpt_integration",
            "firebase_storage"
        ],
        "temp_directory": analyzer.temp_dir,
        "temp_directory_exists": os.path.exists(analyzer.temp_dir),
        "opencv_version": cv2.__version__,
        "server_time": datetime.now().isoformat()
    }

@app.post("/test_upload")
async def test_upload(
    video_file: UploadFile = File(None),
    audio_file: UploadFile = File(None)
):
    """íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    result = {
        "video_received": False,
        "audio_received": False,
        "video_size": 0,
        "audio_size": 0,
        "video_filename": None,
        "audio_filename": None
    }
    
    try:
        if video_file:
            content = await video_file.read()
            result["video_received"] = True
            result["video_size"] = len(content)
            result["video_filename"] = video_file.filename
            logger.info(f"âœ… ë¹„ë””ì˜¤ ìˆ˜ì‹ : {video_file.filename}, {len(content)} bytes")
        
        if audio_file:
            content = await audio_file.read()
            result["audio_received"] = True
            result["audio_size"] = len(content)
            result["audio_filename"] = audio_file.filename
            logger.info(f"âœ… ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {audio_file.filename}, {len(content)} bytes")
        
        return result
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== GPT í”¼ë“œë°± API ====================

@app.post("/ask", response_model=GptResponse)
async def ask_gpt(request: AskRequest):
    """GPT í”¼ë“œë°± ìš”ì²­"""
    if not client:
        return {"content": "OpenAI APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•˜ê³  ë¶„ì„ë ¥ ìˆëŠ” ë©´ì ‘ê´€ì´ì•¼. ì‚¬ìš©ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³ , ì‹¤ìš©ì ì¸ í”¼ë“œë°± ë° ê°œì„ ì ì„ ì§§ê³  ëª…í™•í•˜ê²Œ ì•Œë ¤ì¤˜"},
                {"role": "user", "content": f"ë©´ì ‘ ì§ˆë¬¸: {request.message}\nì‚¬ìš©ì ë‹µë³€: [ì‚¬ìš©ìê°€ ì…ë ¥í•œ ëŒ€ë‹µ ë‚´ìš©]"}
            ],
            max_tokens=300
        )
        answer = chat_completion.choices[0].message.content
        return {"content": answer}
    
    except Exception as e:
        return {"content": f"ì—ëŸ¬ ë°œìƒ: {str(e)}"}

# ==================== ìš”ì•½ API ====================

@app.post("/summarize", response_model=SummaryResponse)
def summarize(req: SummaryRequest):
    """í…ìŠ¤íŠ¸ ìš”ì•½"""
    result = summarize_text(req.content, req.role)
    return {"summary": result}

# ==================== Firebase íˆìŠ¤í† ë¦¬ API ====================

@app.post("/save_history")
def save_history(item: HistoryItem):
    """ì§ˆë¬¸/ë‹µë³€/í”¼ë“œë°± ì €ì¥"""
    if not firebase_initialized:
        return {"status": "error", "message": "Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    try:
        history_id = str(uuid.uuid4())
        summarized_question = summarize_text(item.question, role="ì§ˆë¬¸")
        summarized_answer = summarize_text(item.answer, role="ì‘ë‹µ")
        summarized_feedback = summarize_text(item.feedback, role="í”¼ë“œë°±")

        ref = db.reference(f'history/{item.user_id}/{history_id}')
        ref.set({
            'question': summarized_question,
            'answer': summarized_answer,
            'feedback': summarized_feedback
        })

        return {"status": "success", "id": history_id}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.get("/get_history/{user_id}")
def get_history(user_id: str):
    """íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    if not firebase_initialized:
        return {"status": "error", "message": "Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    try:
        ref = db.reference(f'history/{user_id}')
        data = ref.get()
        return data or {}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/delete_history")
def delete_history(req: DeleteRequest):
    """íˆìŠ¤í† ë¦¬ ì‚­ì œ"""
    if not firebase_initialized:
        raise HTTPException(status_code=500, detail="Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        ref = db.reference(f"history/{req.user_id}/{req.history_id}")
        ref.delete()
        return {"message": "ì‚­ì œ ì„±ê³µ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

# ==================== ì§ˆë¬¸ ìƒì„± API ====================

@app.get("/generate_question/{user_id}", response_model=GptResponse)
def generate_question(user_id: str):
    """ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ì§ˆë¬¸ ìƒì„±"""
    if not firebase_initialized:
        return {"content": "ê°€ì¥ ìì‹  ìˆëŠ” í”„ë¡œì íŠ¸ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
    
    if not client:
        return {"content": "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ ê²½í—˜ì„ ë§ì”€í•´ì£¼ì„¸ìš”."}
    
    try:
        ref = db.reference(f'history/{user_id}')
        history = ref.get()

        previous_questions = []
        if history:
            for record in history.values():
                if "question" in record:
                    previous_questions.append(record["question"])

        prompt = f"""
ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„ í–ˆìŠµë‹ˆë‹¤:
{chr(10).join(previous_questions)}

ì´ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ë©´ì ‘ ì§ˆë¬¸ì„ í•˜ë‚˜ë§Œ ìƒì„±í•´ì¤˜.
"""
        chat_completion = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§€í•œ ì§ë¬´ ë©´ì ‘ê´€ì´ì•¼."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100
        )

        question = chat_completion.choices[0].message.content
        return {"content": question}
    
    except Exception as e:
        return {"content": f"ì—ëŸ¬ ë°œìƒ: {str(e)}"}

# ==================== ì—°ê´€ ì§ˆë¬¸ API ====================

@app.post("/interview/start", response_model=StartInterviewResponse)
def interview_start(req: StartInterviewRequest):
    """ë©´ì ‘ ì„¸ì…˜ ì‹œì‘"""
    session_id = str(uuid.uuid4())
    SESSIONS[session_id] = {
        "user_id": req.user_id,
        "role": req.role,
        "turns": [],
        "created_at": time.time(),
    }

    if firebase_initialized:
        try:
            ref = db.reference(f"sessions/{req.user_id}/{session_id}")
            ref.set({
                "meta": {
                    "role": req.role or "",
                    "created_at": time.time(),
                    "seed_question": req.seed_question or "",
                },
                "turns": {}
            })
        except Exception as e:
            logger.warning(f"Firebase ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    first_q = req.seed_question or "ê°€ì¥ ìì‹  ìˆëŠ” í”„ë¡œì íŠ¸ë¥¼ ê³¨ë¼ ëª©í‘œì™€ ë³¸ì¸ ê¸°ì—¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
    return {"session_id": session_id, "first_question": first_q}

@app.post("/interview/next", response_model=NextInterviewResponse)
def interview_next(req: NextInterviewRequest):
    """ë‹¤ìŒ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±"""
    if not client:
        return {
            "question": "ê·¸ ê²½í—˜ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "tag": "ë¬¸ì œí•´ê²°",
            "difficulty": "ì¤‘",
            "feedback": "êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ë³´ì„¸ìš”."
        }
    
    sess = SESSIONS.get(req.session_id)
    if not sess or sess["user_id"] != req.user_id:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ ì—†ìŒ or user_id ë¶ˆì¼ì¹˜")

    recent = [{"q": t["q"], "a": t["a"]} for t in sess["turns"]]
    prompt = build_user_prompt(sess.get("role"), req.last_question, req.user_answer, recent)

    chat = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
        max_tokens=300,
        temperature=0.4
    )

    content = chat.choices[0].message.content
    try:
        data = json.loads(content)
    except Exception:
        data = {
            "question": content.strip(),
            "tag": "ë¬¸ì œí•´ê²°",
            "difficulty": "ì¤‘",
            "feedback": "ìˆ˜ì¹˜ì™€ ë³¸ì¸ ì—­í• ì„ êµ¬ì²´ì ìœ¼ë¡œ ë§í•´ë³´ì„¸ìš”."
        }

    turn = {
        "q": req.last_question,
        "a": req.user_answer,
        "followup": data,
        "ts": time.time()
    }
    sess["turns"].append(turn)

    if firebase_initialized:
        try:
            ref = db.reference(f"sessions/{req.user_id}/{req.session_id}/turns")
            ref.push(turn)
        except Exception as e:
            logger.warning(f"Firebase í„´ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    return data

# ==================== ìê¸°ì†Œê°œì„œ API ====================

@app.get("/get_resume/{user_id}")
def get_resume(user_id: str):
    """ìê¸°ì†Œê°œì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not firebase_initialized:
        raise HTTPException(status_code=500, detail="Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        ref = db.reference(f"resumes/{user_id}")
        resume_data = ref.get()

        if not resume_data:
            raise HTTPException(status_code=404, detail="ìê¸°ì†Œê°œì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        return {
            "status": "success",
            "resume": resume_data
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìê¸°ì†Œê°œì„œ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")

@app.get("/match_resume_question/{user_id}")
def match_resume_question(user_id: str, retry: int = 0):
    """ìê¸°ì†Œê°œì„œ ê¸°ë°˜ ë§ì¶¤ ì§ˆë¬¸ ìƒì„±"""
    try:
        logger.info(f"========== match_resume_question ì‹œì‘ (retry={retry}) ==========")
        logger.info(f"[1ë‹¨ê³„] user_id: {user_id}")

        # Firebase ì´ˆê¸°í™” í™•ì¸
        if not firebase_initialized:
            logger.warning("[WARNING] Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜")
            default_questions = [
                "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ì™€ ê·¸ ê²½í—˜ì—ì„œ ë°°ìš´ ì ì„ ë§ì”€í•´ì£¼ì„¸ìš”.",
                "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì„ í•´ê²°í•œ ê²½í—˜ì´ ìˆë‹¤ë©´ ê³µìœ í•´ì£¼ì„¸ìš”."
            ]
            return {
                "content": random.choice(default_questions),
                "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸",
                "note": "Firebase ì—°ê²° ì—†ì´ ê¸°ë³¸ ì§ˆë¬¸ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
            }

        # Firebaseì—ì„œ ìê¸°ì†Œê°œì„œ ê°€ì ¸ì˜¤ê¸°
        ref_resume = db.reference(f"resumes/{user_id}")
        resume = ref_resume.get()
        logger.info(f"[2ë‹¨ê³„] Firebase resumes/{user_id} ì¡°íšŒ ê²°ê³¼:")
        logger.info(f"  - resume íƒ€ì…: {type(resume)}")

        # ìê¸°ì†Œê°œì„œê°€ ì—†ìœ¼ë©´ ì¬ì‹œë„ ë˜ëŠ” ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜
        if not resume:
            logger.warning(f"[WARNING] ìê¸°ì†Œê°œì„œ ì—†ìŒ (ì‹œë„ {retry + 1}/3)")
            
            if retry < 2:
                import time
                time.sleep(0.5)
                return match_resume_question(user_id, retry + 1)
            
            logger.info("[FALLBACK] ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜")
            default_questions = [
                "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ì™€ ê·¸ ê²½í—˜ì—ì„œ ë°°ìš´ ì ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
            ]
            return {
                "content": random.choice(default_questions),
                "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸",
                "note": "ìê¸°ì†Œê°œì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì§ˆë¬¸ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
            }

        # OpenAI í™•ì¸
        if not client:
            logger.warning("[WARNING] OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ - ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜")
            return {
                "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸",
                "note": "OpenAI API ì—†ì´ ê¸°ë³¸ ì§ˆë¬¸ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
            }

        # ìê¸°ì†Œê°œì„œ ë‚´ìš© ì •ë¦¬
        resume_text = "\n".join([
            f"ì§€ì›ì§ë¬´: {resume.get('job_role', '')}",
            f"í”„ë¡œì íŠ¸ ê²½í—˜: {resume.get('project_experience', '')}",
            f"ê°•ì : {resume.get('strength', '')}",
            f"ì•½ì : {resume.get('weakness', '')}",
            f"ì§€ì›ë™ê¸°: {resume.get('motivation', '')}"
        ])
        logger.info(f"[3ë‹¨ê³„] resume_text ì •ë¦¬ ì™„ë£Œ")

        # Firebaseì˜ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ì „ì²´ ë¶ˆëŸ¬ì˜¤ê¸°
        ref_questions = db.reference("ë©´ì ‘ì§ˆë¬¸/ì§ì—…ì§ˆë¬¸")
        all_categories = ref_questions.get()
        logger.info(f"[4ë‹¨ê³„] ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ")

        if not all_categories:
            logger.warning("[WARNING] ì§ˆë¬¸ DB ì—†ìŒ")
            return {
                "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸"
            }
        
        # ì¹´í…Œê³ ë¦¬ ëª©ë¡ ìƒì„±
        categories_list = []
        for big_cat, subcats in all_categories.items():
            if subcats and isinstance(subcats, dict):
                for small_cat in subcats.keys():
                    categories_list.append(f"{big_cat} / {small_cat}")
        
        if not categories_list:
            return {
                "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸"
            }
        
        categories_text = "\n".join(categories_list)
        logger.info(f"[5ë‹¨ê³„] ì´ {len(categories_list)}ê°œ ì¹´í…Œê³ ë¦¬ ìƒì„±")

        # GPTì—ê²Œ ë§¤ì¹­ ìš”ì²­
        prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œì„œ ë‚´ìš©ì…ë‹ˆë‹¤:
{resume_text}

ì•„ë˜ëŠ” ë©´ì ‘ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì…ë‹ˆë‹¤:
{categories_text}

ì´ ìê¸°ì†Œê°œì„œì— ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ì¹´í…Œê³ ë¦¬ 1ê°œë¥¼ ê³¨ë¼ë¼.
í˜•ì‹ì€ ë°˜ë“œì‹œ 'ëŒ€ë¶„ë¥˜ / ì†Œë¶„ë¥˜'ë¡œë§Œ ì¶œë ¥í•´ë¼."""
        
        chat = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë©´ì ‘ê´€ì´ë‹¤. ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ì½ê³  ê°€ì¥ ê´€ë ¨ëœ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ë¥¼ íŒë‹¨í•œë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.3
        )

        match = chat.choices[0].message.content.strip()
        logger.info(f"[6ë‹¨ê³„] GPT ì‘ë‹µ: {match}")

        if "/" not in match:
            return {
                "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸"
            }
        
        big_cat, small_cat = [x.strip() for x in match.split("/", 1)]
        
        # ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        matched_ref = db.reference(f"ë©´ì ‘ì§ˆë¬¸/ì§ì—…ì§ˆë¬¸/{big_cat}/{small_cat}")
        questions = matched_ref.get()
        
        if not questions:
            return {
                "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "match": match
            }
        
        # ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
        if isinstance(questions, list):
            question_list = questions
        elif isinstance(questions, dict):
            question_list = list(questions.values())
        else:
            return {
                "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "match": match
            }

        selected_question = random.choice(question_list)
        logger.info(f"[7ë‹¨ê³„] ì„ íƒëœ ì§ˆë¬¸: {selected_question}")
        logger.info("========== match_resume_question ì„±ê³µ ==========")

        return {
            "content": selected_question,
            "match": match
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "content": "ìì‹ ì˜ ê°•ì ì„ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "match": "ì¼ë°˜ / ê¸°ë³¸ì§ˆë¬¸",
            "note": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }

# ==================== 404 ì—ëŸ¬ í•¸ë“¤ëŸ¬ ====================

@app.exception_handler(404)
async def not_found_handler(request, exc):
    """404 ì—ëŸ¬ ë°œìƒ ì‹œ ìì„¸í•œ ë¡œê·¸ ì¶œë ¥"""
    logger.error(f"âŒ 404 Not Found: {request.method} {request.url.path}")
    logger.error(f"   ìš”ì²­ í—¤ë”: {dict(request.headers)}")
    
    return {
        "error": "Not Found",
        "message": f"ê²½ë¡œ '{request.url.path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "method": request.method,
        "available_endpoints": [
            "POST /analyze_video",
            "GET /analyze_video",
            "POST /api/analyze_video",
            "POST /analyze-video",
            "GET /",
            "GET /status"
        ],
        "suggestion": "ì˜¬ë°”ë¥¸ ì—”ë“œí¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    }

# ==================== OPTIONS ìš”ì²­ ì²˜ë¦¬ ====================

@app.options("/analyze_video")
@app.options("/api/analyze_video")
@app.options("/analyze-video")
async def options_handler():
    """CORS Preflight ìš”ì²­ ì²˜ë¦¬"""
    return {"status": "ok"}

# ==================== ì„œë²„ ì‹¤í–‰ ====================

if __name__ == "__main__":
    import uvicorn
    print("=== ğŸš€ í†µí•© ë©´ì ‘ ë¶„ì„ ì„œë²„ ì‹œì‘ (404 í•´ê²° ë²„ì „) ===")
    print("âœ“ ì˜ìƒ ë¶„ì„: POST/GET ëª¨ë‘ ì§€ì›")
    print("âœ“ ì—ëŸ¬ í•¸ë“¤ë§: ìì„¸í•œ ë¡œê·¸ ì¶œë ¥")
    print("âœ“ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: íŒŒì¼ ì—†ì–´ë„ ì‘ë™")
    print("âœ“ ì˜ìƒ ë¶„ì„: 3í”„ë ˆì„ ê°„ê²© ì´˜ì´˜í•œ ë¶„ì„")
    print("âœ“ ì‹œì„  ì¶”ì : ëˆˆ ê²€ì¶œ + í™”ë©´ ì¤‘ì•™ ê±°ë¦¬ ê³„ì‚°")
    print("âœ“ ìŒì„± ì •ë°€: ì¶”ì„ìƒˆ ì¢…ë¥˜ë³„ ì¹´ìš´íŠ¸")
    print("âœ“ GPT í†µí•©: í”¼ë“œë°±, ì§ˆë¬¸ ìƒì„±, ìš”ì•½")
    print(f"âœ“ Firebase: {'âœ… ì—°ê²°ë¨' if firebase_initialized else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"âœ“ OpenAI: {'âœ… ì—°ê²°ë¨' if client else 'âŒ ë¹„í™œì„±í™”'}")
    print("")
    print("ğŸ“¡ ë¡œì»¬ ì ‘ì†: http://localhost:8000")
    print("ğŸ“± ì•ˆë“œë¡œì´ë“œ ì ‘ì†: http://[í•«ìŠ¤íŒŸIP]:8000")
    print("   - í˜„ì¬ ì„¤ì •: http://172.20.10.4:8000")
    print("ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs")
    print("")
    print("ğŸ”¥ ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:")
    print("   POST /analyze_video - ì˜ìƒ ë¶„ì„ (ë©”ì¸)")
    print("   GET  /analyze_video - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
    print("   POST /ask - GPT í”¼ë“œë°±")
    print("   POST /interview/start - ë©´ì ‘ ì„¸ì…˜ ì‹œì‘")
    print("   POST /interview/next - ê¼¬ë¦¬ ì§ˆë¬¸")
    print("   GET  /match_resume_question/{user_id} - ë§ì¶¤ ì§ˆë¬¸")
    print("================================")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")